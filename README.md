# Fine-Tuning Open Source LLMs

This repo is part of the [Certified Cloud Native Applied Generative AI Engineer](https://docs.google.com/document/d/15usu1hkrrRLRjcq_3nCTT-0ljEcgiC44iSdvdqrCprk/edit?usp=sharing) program. It covers the fifth quarter of the course work:

## Quarter 6: Fine-Tuning Open-Source Large Language Models

This comprehensive course is designed to guide learners through the process of fine-tuning open-source Large Language Models (LLMs) such as Meta LLaMA 3.1 using PyTorch, with a particular emphasis on cloud-native training and deployment. The course covers everything from the fundamentals to advanced concepts, ensuring students acquire both theoretical knowledge and practical skills.
The journey begins with an introduction to LLMs, focusing on their architecture, capabilities, and the specific features of Meta LLaMA 3.1. Students will also set up their development environment, including tools like Anaconda, Jupyter Notebooks, and PyTorch, to prepare for hands-on learning.

Fine-tuning Meta LLaMA 3 with PyTorch forms a significant part of the course. Students will delve into the architecture of Meta LLaMA 3.1, learn how to load pre-trained models, and apply fine-tuning techniques. 

The course culminates in a capstone project, where students apply all the skills they have learned to fine-tune and deploy Meta LLaMA 3.1 on a chosen platform. This project allows students to demonstrate their understanding and proficiency in the entire process, from data preparation to cloud-native deployment. 

### Study Material

[Introducing Llama 3.1: Our most capable models to date](https://ai.meta.com/blog/meta-llama-3-1/)

[Step-By-Step Tutorial: How to Fine-tune Llama 3 (8B) with Unsloth + Google Colab & deploy it to Ollama](https://www.reddit.com/r/LocalLLaMA/comments/1e416fo/stepbystep_tutorial_how_to_finetune_llama_3_8b/)

[Working with Llama 3](https://www.datacamp.com/courses/working-with-llama-3)

[Insanely Fast LLAMA-3 on Groq Playground and API for FREE](https://www.youtube.com/watch?v=ySwJT3Z1MFI)

[Introducing Llama-3-Groq-Tool-Use Models](https://wow.groq.com/introducing-llama-3-groq-tool-use-models/)

[Llama 3 Groq 8B Tool Use - Install and Do Actual Function Calling Locally](https://www.youtube.com/watch?v=dfGQkF4f_-o)

[Superfast RAG with Llama 3 and Groq](https://www.youtube.com/watch?v=ne-lrm0n0bg)

[Groqâ€™s open-source Llama AI model tops leaderboard, outperforming GPT-4o and Claude in function calling](https://venturebeat.com/ai/groq-open-source-llama-ai-model-tops-leaderboard-outperforming-gpt-4o-and-claude-in-function-calling/)

[How to Fine Tune Llama 3 LLM (or) any LLM in Colab | PEFT | Unsloth](https://www.youtube.com/watch?v=sNJsMycv5Pk)



